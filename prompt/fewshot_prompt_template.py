# =====================================================
# 0) í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
# =====================================================
# .env íŒŒì¼ì— ì €ì¥ëœ OPENAI_API_KEYë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
from dotenv import load_dotenv
import os

load_dotenv()  # .env íŒŒì¼ì„ ì½ì–´ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    # API í‚¤ê°€ ì—†ìœ¼ë©´ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ê³  ì—ëŸ¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    raise RuntimeError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# =====================================================
# 1) LLM ê°ì²´ ìƒì„±
# =====================================================
# langchain_openai íŒ¨í‚¤ì§€ì˜ ChatOpenAI í´ë˜ìŠ¤ë¡œ LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
from langchain_openai import ChatOpenAI

# temperature=0 ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ë§¤ë²ˆ ë™ì¼í•œ ë‹µë³€ì„ ì–»ë„ë¡ ê³ ì •í•©ë‹ˆë‹¤.
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# =====================================================
# 2) Few-Shot ì˜ˆì œ ë° í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
# =====================================================
from langchain_core.prompts.few_shot import FewShotPromptTemplate
from langchain_core.prompts import PromptTemplate

# 2-1) ì˜ˆì œ ì…ë ¥-ì¶œë ¥ ìŒì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜
examples = [
    {
        "question": "ìŠ¤í‹°ë¸Œ ì¡ìŠ¤ì™€ ì•„ì¸ìŠˆíƒ€ì¸ ì¤‘ ëˆ„ê°€ ë” ì˜¤ë˜ ì‚´ì•˜ë‚˜ìš”?",
        "answer": "ì•„ì¸ìŠˆíƒ€ì¸"
    },
    {
        "question": "ë„¤ì´ë²„ì˜ ì°½ë¦½ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
        "answer": "ì´í•´ì§„"
    },
    {
        "question": "ì—°ì‚°êµ°ì€ ì–´ëŠ ì—°ë„ì— ì¦‰ìœ„í–ˆë‚˜ìš”?",
        "answer": "1504ë…„"
    }
]

# 2-2) ì˜ˆì œ í•˜ë‚˜ë¥¼ ì¶œë ¥í•  ë•Œ ì‚¬ìš©í•  í¬ë§·ì„ ì •ì˜
#    {question}ê³¼ {answer} ìë¦¬ì— ì‹¤ì œ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.
example_prompt = PromptTemplate(
    template="Question: {question}\nAnswer: {answer}",
    input_variables=["question", "answer"],
)

# 2-3) FewShotPromptTemplate ìƒì„±
#    - examples: ì‹¤ì œ ì˜ˆì œ ë¦¬ìŠ¤íŠ¸
#    - example_prompt: ìœ„ì—ì„œ ì •ì˜í•œ í¬ë§·, questionê³¼ answerë¥¼ ì–´ë–¤ í˜•íƒœë¡œ ë„£ì„ì§€ ì •ì˜
#    - suffix: ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  ìµœì¢… í”„ë¡¬í”„íŠ¸ ëë¶€ë¶„, ëª¨ë“  ì˜ˆì œë¥¼ ë³´ì—¬ì¤€ ë’¤ ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ê¸° ìœ„í•´ ë¶™ì´ëŠ” í…ìŠ¤íŠ¸
#    - input_variables: ì‚¬ìš©ì ì§ˆë¬¸ ë³€ìˆ˜ ì´ë¦„
#    - example_separator(ì„ íƒ) : ì˜ˆì œ ì‚¬ì´ êµ¬ë¶„ì , ê¸°ë³¸ê°’ìš´ \n\n / ë³€ê²½ ê°€ëŠ¥
#    - prefix(ì„ íƒ) : ì˜ˆì œ ì•ì— ë¶™ì¼ ì´ˆê¸° ì§€ì‹œë¬¸, ì˜ˆì œê°€ ë‚˜ì˜¤ê¸° ì „ ëª¨ë¸ì—ê²Œ íƒœìŠ¤í¬ ì„¤ëª… ë“±ì„ ë¯¸ë¦¬ ë˜ì§ˆë•Œ ì‚¬ìš©
few_shot_prompt = FewShotPromptTemplate(
    # prefix ì˜µì…˜ ì¶”ê°€
    prefix="ë‹¤ìŒ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n", # ìƒëµ ê°€ëŠ¥
    examples=examples,
    example_prompt=example_prompt,
    suffix="Question: {question}\n",
    input_variables=["question"],
    example_separator="\n\n"  # ì˜ˆì œ ì‚¬ì´ ì¤„ë°”ê¿ˆ ë‘ ì¤„ë¡œ êµ¬ë¶„, ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒëµ ê°€ëŠ¥
)

# =====================================================
# 3) ì¶œë ¥ íŒŒì„œ ë° GraphState ì •ì˜
# =====================================================
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, START, END
from pydantic import BaseModel

# 3-1) GraphState í´ë˜ìŠ¤
#    - stateì— ë‹´ê¸¸ ë°ì´í„° êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
#    - question: ì‚¬ìš©ì ì§ˆë¬¸(í•„ìˆ˜)
#    - answer: ëª¨ë¸ì´ ìƒì„±í•œ ë‹µë³€(ì´ˆê¸°ê°’ì€ ë¹ˆ ë¬¸ìì—´)
class GraphState(BaseModel):
    question: str
    answer: str = ""

# =====================================================
# 4) ë…¸ë“œ í•¨ìˆ˜ ì •ì˜: few_shot_node
# =====================================================
def few_shot_node(state: GraphState) -> dict:
    """
    1) Few-Shot í”„ë¡¬í”„íŠ¸ ìƒì„±
    2) LLM í˜¸ì¶œ
    3) ë¬¸ìì—´ ì¶œë ¥ íŒŒì‹±
    4) ê²°ê³¼ë¥¼ {'answer': ...} í˜•íƒœë¡œ ë°˜í™˜
    """
    # ì²´ì¸: few_shot_prompt â†’ llm â†’ StrOutputParser()
    chain = few_shot_prompt | llm | StrOutputParser()
    # invokeì— ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì…ë ¥ì„ ë„˜ê²¨ì¤ë‹ˆë‹¤.
    answer = chain.invoke({"question": state.question})
    # ìƒíƒœì˜ answer í•„ë“œë§Œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ dictë¡œ ë°˜í™˜
    return {"answer": answer}

# =====================================================
# 5) StateGraph êµ¬ì„± ë° ì‹¤í–‰
# =====================================================
# 5-1) StateGraph ìƒì„±: ìƒíƒœ ìŠ¤í‚¤ë§ˆë¡œ GraphState ì‚¬ìš©
pipeline = StateGraph(GraphState)

# 5-2) ë…¸ë“œ ì¶”ê°€
pipeline.add_node("few_shot", few_shot_node)

# 5-3) ì‹œì‘(START) â†’ few_shot â†’ ë(END) ì—°ê²°
pipeline.add_edge(START, "few_shot")
pipeline.add_edge("few_shot", END)

# 5-4) ê·¸ë˜í”„ ì»´íŒŒì¼
graph = pipeline.compile()

# =====================================================
# 5) ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° ë° ê²°ê³¼ ì¶œë ¥
# =====================================================
# ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ë„ìš°ê³ , ì‚¬ìš©ìê°€ ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë„ë¡ í•¨
user_question = input("ğŸ‘‰ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")

# PromptTemplateì´ ì¡°í•©í•œ ì „ì²´ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ ìƒì„±
full_prompt = few_shot_prompt.format(question=user_question)

# prefix, example1~N, suffix ìˆœì„œëŒ€ë¡œ ì¶œë ¥
print("\n===== ìƒì„±ëœ ì „ì²´ í”„ë¡¬í”„íŠ¸ =====")
print(full_prompt)
print("================================\n")

# GraphState ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ ê·¸ë˜í”„ì— ë„˜ê¹€
result = graph.invoke(GraphState(question=user_question))

# ìµœì¢… answer ì¶œë ¥
print("\nğŸ’¡ ë‹µë³€:", result["answer"])